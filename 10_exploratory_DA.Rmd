---
title: "Exploratory Data Analysis (EDA)"
description: | 
  Having Fun
output: 
  distill::distill_article:
    toc: true
---

```{r setup, include=FALSE, purl=FALSE, message=FALSE}

library(knitr)
library(here)
suppressPackageStartupMessages(library(tidyverse))

# may need to specify this option to get this to properly knit/print:
mapview::mapviewOptions(fgb = FALSE)

```

::: {.obj}
**Learning objectives**

-   Understand when and how to carry out an Exploratory Data Analysis (EDA)
-   Practice an EDA with tools and data from previous modules
:::

## What's an EDA?

An [Exploratory Data Analysis, or EDA](https://en.wikipedia.org/wiki/Exploratory_data_analysis), is a way to approach the analysis of datasets that allows the data analyst to explore data and come up with hypotheses to test from that exploration. In the book, [*R for Data Science*](https://r4ds.had.co.nz/exploratory-data-analysis.html), EDA is described as an iterative cycle where you:

> 1.  Generate questions about your data.
> 2.  Search for answers by visualizing, transforming, and modeling your data.
> 3.  Use what you learn to refine your questions and/or generate new questions.

In previous modules, we've covered the building blocks to perform an EDA in R, and in this module, we're going to bring it all together and perform an EDA on the groundwater measurements dataset[^1] and CalEnviroscreen 3.0 data[^2].

[^1]: DWR [Periodic Groundwater level database](<https://data.cnra.ca.gov/dataset/periodic-groundwater-level-measurements>).

[^2]: OEHHA [CalEnviroscreen 3.0 data](https://oehha.ca.gov/calenviroscreen/report/calenviroscreen-30).

We will focus on generating questions, and answering them through visualization.[^3]

[^3]: Statistical modeling is beyond the scope of this module, but if you are interested, you can read more about statistical modeling in R [here](https://r4ds.had.co.nz/model-basics.html).


## Generate questions

Our dataset contains observations of groundwater level measurements at monitoring stations throughout Sacramento County, and these observations have been spatially joined by census tract to CalEnviroScreen 3.0 (CES) scores.

To begin, let's ask a few general questions:  

1. What well uses (e.g., domestic, public, agricultural) are most common, and where are they located?  
2. How do well depths compare between well uses?  
3. What are the historical trends in groundwater elevation?  
4. How do CES scores relate to groundwater level trends?

We will use the following packages in our EDA, so we load them now.

```{r pkgs}

library(here)
library(tidyverse)
library(sf)
library(mapview)

```


## Searching for Answers

First we need to load our data, which we created in the module on [joins and binds](08_joins.html).

```{r import-jb-data}

# groundwater level measurements joined to stations, perforations, and CES data
gwl <- read_rds(here("data", "sacramento_gw_data_w_calenviro.rds"))

# check class, dim, names to refresh memory
class(gwl)
dim(gwl)
names(gwl)
```

We might want to `View(gwl)` these data to refresh our memory. Remember when View()`ing data in RStudio, that only 50 columns are shown at a time, so you need to click the arrows in the top navigation bar to move between sets of 50 columns.  

<aside>

```{r manyrows, echo = FALSE}
knitr::include_graphics(here("images","manyrows.png"))
```

</aside>

It appears that we have two columns with "County" information, so let's drop the column from CES and keep the one from the groundwater level dataset.

```{r gwl-clean}
gwl <- select(gwl, -`California County`)
```

Finally, let's keep in mind that the structure of these data are that there are many samples per well.


### Well use

What well uses are most common? We can answer this with `table(gwl$WELL_USE)`, but let's do the same thing with {dplyr} functions.

```{r well-use-count}
gwl %>% 
  count(WELL_USE) %>% # group by well use and summarise the count
  arrange(desc(n))    # sort in decreasing order 
```

We could have come to this same table by way of a plot.

```{r well-use-plot}

gwl %>% 
  ggplot(aes(WELL_USE)) +
  geom_bar() +
  coord_flip()

```

Cleaning things up a bit.

```{r well-use-plot2}

p1 <- gwl %>% 
  count(WELL_USE) %>%   # group by well use and summarise the count
  arrange(desc(n)) %>%  # sort in decreasing order 
  filter(!is.na(WELL_USE)) %>% # remove NA well uses
  ggplot(aes(fct_reorder(WELL_USE, n), n)) + # reorder well use by n
  geom_col(aes(fill = WELL_USE)) +    # use column geometry
  coord_flip() +  # flip x and y axes
  labs(title = "Monitoring well use", 
       subtitle = "Sacramento County",
       x = "", y = "Count") +
  guides(fill = FALSE) # remove colorbar

p1
```

### Well location

Well location is a spatial question, and lucky for us these are spatial data! Recall from our last module [how to convert a dataframe to an sf object](09_intro_mapmaking.html#converting-a-dataframe-to-sf). We know the well coordinates are in NAD83 (EPSG 4269), so we can convert this object to an sf object class, and also bring in the Sacramento county polygon shapefile for plotting.

```{r gwl-to-sf}

# convert gwl from dataframe to sf
gwl <- st_as_sf(gwl, 
                coords = c("LONGITUDE", "LATITUDE"), # note x goes first
                crs    = 4269,                       # projection, NAD83
                remove = FALSE) %>%                  # don't remove lat/lon
  st_transform(3310) # convert to geographic CRS

# verify transformation worked
class(gwl)

# also read in the Sacramento county shapefile for plotting
# and transform it to the same crs as gwl
sac <- st_read(here("data", "shp", "sac", "sac_county.shp")) %>% 
  st_transform(st_crs(gwl))

# verify gwl points and sac polygon are in the same crs
st_crs(gwl)$epsg == st_crs(sac)$epsg

```

Let's plot the well use in Sacramento County, similar to what we did in the previous module.

```{r gwl-map}

# because we're only plotting location, which doesn't change between 
# measurements, we slice the first observation per SITE_CODE
gwl_minimal <- gwl %>% 
  filter(!is.na(WELL_USE)) %>% # remove wells without a well use
  group_by(SITE_CODE) %>%      # take first well per site code
  slice(1) 

# map
p2 <- ggplot() +
  geom_sf(data = sac) + 
  geom_sf(data = gwl_minimal, aes(color = WELL_USE), alpha = 0.4) +
  facet_wrap(~WELL_USE) +
  guides(color = FALSE) +
  theme_void()

p2
  
```

The {patchwork} R package is great for combining plots. We can combine the previous 2 plots with a simple `+` once patchwork is loaded. 

```{r patchwork, out.width="100%"}
library(patchwork)

p1 + p2
```

These plots tell us a lot about the distribution of monitoring wells in Sacramento County. For instance, they show that irrigation and residential wells are among the most common known well uses. Interestingly, a substantial number of wells have an unknown use. Irrigation and residential wells appear collocated. 



:::challenge

<font color="#009E73">**Challenge 1: Grouped summary**</font> 

 - What's the average number of samples at each SITE_CODE per WELL_USE?
 - Can you express the distribution of samples at each SITE_CODE per WELL_USE as a boxplot?
 
:::

<details>
  <summary class="challenge-ans-title">**Click for Answers!**</summary>
  <div class="challenge-ans-body">


```{r chal-1a, eval=TRUE, echo=TRUE}

# group by the site code and well use and count
count(gwl, SITE_CODE, WELL_USE) %>% 
  pull(n) %>% 
  mean()
```

```{r chal-1b}

# express as boxplot of number of samples per site code, at each well use
count(gwl, SITE_CODE, WELL_USE) %>% 
  ggplot(aes(WELL_USE, n)) + 
  geom_boxplot() +
  # limit y axis scale to focus on main bulk of distribution
  coord_cartesian(ylim = c(0, 250)) 

```


  </div>
</details>



### Well depths

Now that we understand a bit about the relative proportion and spatial distribution of wells, let's compare total completed depths, which measure how deep the well is and all else being equal, relates to the well's ability to access groundwater. 

We made a plot that explored these trends in the previous mapmaking module.

```{r gwl-depth, echo = FALSE}
knitr::include_graphics(here("results", "sac_well_depth_type.png"))
```

We have the spatial distribution of these values, but now let's summarize the distribution of well depth value themselves.

```{r gwl-depth-boxplot}

gwl_minimal %>% 
  ggplot(aes(WELL_USE, WELL_DEPTH)) +
  geom_boxplot() + 
  coord_flip(ylim = c(0,1000)) # zoom in on main data distribution

```

It is clear that irrigation wells tend to be much deeper than residential, observation, and stock watering wells. There's about a 70 foot difference between median irrigation and residential well depth. We can calculate this exact difference as follows:

```{r wd-diff}

# median well depths
median_well_depths <- filter(gwl_minimal, 
                             WELL_USE %in% c("Residential", "Irrigation")) %>% 
  group_by(WELL_USE) %>% 
  summarise(med_depth = median(WELL_DEPTH, na.rm = TRUE)) %>% 
  st_drop_geometry() # don't need spatial data here

median_well_depths

# difference of median well depths
diff(median_well_depths$med_depth)
```



:::challenge

<font color="#009E73">**Pause and think**</font> 

 - Would we get a different boxplot if we passed in `gwl` instead of `gwl_minimal`? Which is correct to use and why?
 
:::

<details>
  <summary class="challenge-ans-title">**Click for Answers!**</summary>
  <div class="challenge-ans-body">

We would indeed have a different result if we passed in `gwl` instead of `gwl_minimal`. Recall that `gwl` has `r nrow(gwl)` rows but there are `r length(unique(gwl$SITE_CODE))` unique `SITE_CODE`s in `gwl`. If we pass in `gwl` instead of `gwl_minimal`, we're computing a boxplot on duplicate value of `WELL_DEPTH`s for each `SITE_CODE`, where the *number of samples per individual well* can influence the computed summary statistics. It's correct to use `gwl_minimal` because there's only one `WELL_DEPTH` for each `SITE_CODE`.

```{r chal-12a, eval=TRUE, echo=TRUE}

# verify that using gwl v gwl_minimal gives us different results
pbox1 <- gwl_minimal %>% 
  ggplot(aes(WELL_USE, WELL_DEPTH)) +
  geom_boxplot()

pbox2 <- gwl %>% 
  filter(!is.na(WELL_USE)) %>% 
  ggplot(aes(WELL_USE, WELL_DEPTH)) +
  geom_boxplot()

pbox1 + pbox2

```

```{r chal-2b}

# demonstrate differences in median well depth 
gwl %>% 
  group_by(WELL_USE) %>% 
  summarise(med = median(WELL_DEPTH, na.rm = TRUE)) %>% 
  st_drop_geometry()

gwl_minimal %>% 
  group_by(WELL_USE) %>% 
  summarise(med = median(WELL_DEPTH, na.rm = TRUE)) %>% 
  st_drop_geometry()

```
This is all to highlight that it's important to remember what data you're feeding into functions. Many a nightmarish bug has been caused by the data analyst thinking they're data in one form, when it's actually in another!

  </div>
</details>



### Groundwater level change

We've been working mostly with station data above for the `r length(unique(gwl$SITE_CODE))` unique stations. In fact, we could have performed most of our analyses above using only the `stations.csv` file we saw in previous modules. Now we drill down into the groundwater data itself, which contains many more observations, `r nrow(gwl)` rows to be exact. 

Let's start by plotting all depths to groundwater elevations per site. Recall that `GSE_WSE` is the depth to groundwater in feet below land surface.

```{r gwl-change}

gwl %>% 
  ggplot(aes(MSMT_DATE, GSE_WSE, group = SITE_CODE)) +
  geom_line(alpha = 0.5)

```

It generally appears that depth to groundwater is increasing over time (groundwater depletion), but a few clearly erroneous values > 250 feet are impairing the plot. Let's remove these values and replot.

```{r gwl-fix}

gwl <- filter(gwl, GSE_WSE <= 250)

gwl %>% 
  ggplot(aes(MSMT_DATE, GSE_WSE, group = SITE_CODE)) +
  geom_line(alpha = 0.5)

```

Much better!

Now let's facet by well use and look at trend lines over time.

```{r gwl-use-time}

gwl %>% 
  ggplot(aes(MSMT_DATE, GSE_WSE, group = SITE_CODE)) +
  geom_line(alpha = 0.5) +
  facet_wrap(~WELL_USE)

```

Let's tie this back to our spatial data answer the question, "which areas have experienced the largest drop in groundwater levels over their historical period of record?" We'll also impose a constraint that a well must have at least 50 groundwater level measurements, and a historical record that begins in 1980-01-01 or earlier. Residential and irrigation wells have the most data, and we saw above that they overlap in space, so let's zoom into these categories in subsequent analyses. 

```{r largest-drop}

# find SITE_CODEs that meet well use and time constraints
ids_use_time <- gwl %>% 
  filter(WELL_USE %in% c("Residential", "Irrigation"), 
         MSMT_DATE <= "1980-01-01") %>% 
  pull(SITE_CODE) %>% 
  unique()

# ids that meet time constraints and sample constraints
ids_time_samp <- gwl %>% 
  filter(SITE_CODE %in% ids_use_time) %>% 
  count(SITE_CODE) %>% 
  filter(n >= 30) %>% 
  pull(SITE_CODE)

# view ids that meet constraints
ids_time_samp %>% length()
```


Of the `r length(unique(gwl$SITE_CODE))` site codes, `r length(ids_time_samp)`, or about `r round((length(ids_time_samp) / length(unique(gwl$SITE_CODE)))*100)`% meet our constraints. 

These IDs represent *long term monitoring sites* that meet our constraints. We can use them to filter our `gwl` data and calculate the groundwater level change over the period of record.

```{r largest-change-2}

gwl_diff <- gwl %>% 
  # only SITE_CODE meeting time and sample constraints
  filter(SITE_CODE %in% ids_time_samp) %>% 
  group_by(SITE_CODE, WELL_USE) %>% # for each site code and well use
  arrange(MSMT_DATE) %>%            # arrange dates in ascending order
  summarise(t1 = first(MSMT_DATE), # first date
            t2 = last(MSMT_DATE),  # last date
            gse_wse_t1 = first(GSE_WSE),    # first gwl measurement
            gse_wse_t2 = last(GSE_WSE)) %>% # last  gwl measurement 
  mutate(diff = gse_wse_t2 - gse_wse_t1)    # diff btwn last and first gwl
  
gwl_diff
```

Let's map these changes at our `r length(ids_time_samp)` long-term monitoring sites.

```{r largest-change-3 }

ggplot() +
  geom_sf(data = sac) +
  geom_sf(data = gwl_diff, aes(color = diff)) +
  scale_color_viridis_c()

```

Outliers are a fairly common problem in real world data. For some reason, one site shows a -100 change (dark purple dot). Is this a problem with the data or our analysis? Let's inspect it with a plot.

```{r inspect}

id_problem <- gwl_diff %>% 
  filter(diff < -90) %>% 
  pull(SITE_CODE)

gwl %>% 
  filter(SITE_CODE == id_problem) %>% 
  ggplot(aes(MSMT_DATE, GSE_WSE)) +
  geom_line()

```

Ah ha! Everything looks okay, until measured values fall off a cliff around 1990. Let's remove this single observation. Luckily each water level measurement has a unique ID (`WLM_ID`), so we can use this to remove the value, and then recompute our groundwater level difference. Because we have this transformation already in code, it's trivial to rerun this complex operation!

```{r fix-gwl}

# remove one erroneous measurement
gwl <- filter(gwl, WLM_ID != "1345292")

# recompute groundwater level difference
gwl_diff <- gwl %>% 
  # only SITE_CODE meeting time and sample constraints
  filter(SITE_CODE %in% ids_time_samp) %>% 
  group_by(SITE_CODE, WELL_USE) %>% # for each site code and well use
  arrange(MSMT_DATE) %>%            # arrange dates in ascending order
  summarise(t1 = first(MSMT_DATE), # first date
            t2 = last(MSMT_DATE),  # last date
            gse_wse_t1 = first(GSE_WSE),    # first gwl measurement
            gse_wse_t2 = last(GSE_WSE)) %>% # last  gwl measurement 
  mutate(diff = gse_wse_t2 - gse_wse_t1)    # diff btwn last and first gwl

```

Next we can replot our map without this erroneous value, and spruce things up a bit.

```{r preprocess nhd, eval = FALSE}

read_rds(here("data", "nhd_sas.rds")) %>% 
  st_as_sf() %>% 
  filter(GNIS_Name %in% c("American River", "Cosumnes River", "Mokelumne River",
                          "North Mokelumne River","South Mokelumne River","Sacramento River")) %>% 
  st_transform(3310) %>% 
  write_rds(here("data","nhd_sac_major.rds"))

```


```{r gwl-map-gwl-fixed}

ggplot() +
  geom_sf(data = sac) +
  geom_sf(data = gwl_diff, aes(fill = diff), pch = 21) +
  scale_fill_viridis_c("GWL \nchange (ft)", option = "B", direction = -1) +
  facet_wrap(~WELL_USE) +
  labs(title = "Difference in groundwater elevation (ft)",
       subtitle = "For wells with > 30 samples and data from at least 1980-01-01",
       caption = "Larger values indicate groundwater depletion.") +
  theme_minimal()

```

It appears that larger groundwater level changes occur in the interior of Sacramento County. Smaller changes along the boundaries may result from groundwater recharge from surface water. 

Finally, let's examine the changes in groundwater level at the sites that meet our constraints and add linear trendlines. 

```{r largest-change-4}

# go back and grab gwl measurements at the specified site codes
gwl_res_ir <- filter(gwl, 
                     SITE_CODE %in% ids_time_samp)
  
# plot all groundwater levels and a linear trendline
gwl_res_ir  %>% 
  ggplot(aes(MSMT_DATE, GSE_WSE)) +
  geom_line(aes(group = SITE_CODE), alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  facet_wrap(~WELL_USE) +
  labs(x = "", y = "Depth to groundwater (ft)")

```

These trendlines suggest that monitored depths to groundwater have increased during the period of record at the long-term monitoring sites identified by our selection criteria. These declines are likely due groundwater pumping for urban expansion and irrigated agriculture. Remember also, that residential wells were substantially shallower than irrigation wells (around a 70 foot difference in median depth), so these groundwater level changes are likely to be impacting different aquifers. 


### CES scores

Finally, let's incorporate CES scores into our analysis and see how they relate to groundwater level trends. As a first cut, let's just look at the CES percentile (higher indicates a more negative outcome) on a basemap with {mapview}.   

```{r mv-ces, out.wdith = "100%"}
library(mapview)

mapview(sac, alpha.regions = 0, color = "red", lwd = 2, layer.name = "Sac Co") + 
  mapview(select(gwl_minimal, `CES 3.0 Percentile`), # only show CES score in table
          zcol = "CES 3.0 Percentile", layer.name = "CES score")

```

Next, we might be interested to examine the groundwater level decline per census tract at our long-term monitoring sites.

```{r gwl-tract}

# select minimal subset of data to join back to gwl
gwl_diff_df <- st_drop_geometry(gwl_diff) %>% 
  select(SITE_CODE, diff)

# join differenced data back to groundwater level
gwl_ces <- gwl %>% 
  filter(SITE_CODE %in% ids_time_samp) %>% # selection criteria
  group_by(SITE_CODE) %>% # slice 1st row per group as CES scores duplicate
  slice(1) %>% 
  ungroup() %>% 
  left_join(gwl_diff_df, by = "SITE_CODE")  # add groundwater level diff
  

gwl_ces %>% 
  ggplot(aes(diff, `CES 3.0 Percentile`)) +
  geom_point()
```

It appears that if there is any trend at all, there's a slight negative relationship between CES and large groundwater withdrawal. This is likely because CES scores tend to be higher near urban areas, and most groundwater pumping takes place in rural areas away from urban development. To confirm, let's inspect points with a difference in groundwater level >= 25 feet.

```{r mapview-gwl-25}

m1 <- filter(gwl_ces, diff >= 25) %>% 
  select(diff) %>% 
  mapview(zcol = "diff", layer.name = "GWL <br>delcine (ft)")

m1
```

If we toggle the basemap to "Esri World Imagery" it's clear that areas with large groundwater declines are on the leading edges of expanding suburban zones and in rural areas. 

Let's now define a class of monitoring points called `high_priority` that is characterized by high CES scores and large groundwater declines.

```{r focus}

# add a new column "high_priority" if gwl change >= 25 feet and CES >= 50%
gwl_ces <- gwl_ces %>% 
  mutate(high_priority = ifelse(diff >= 25 & `CES 3.0 Percentile` >= 50, TRUE, FALSE))

gwl_ces %>% 
  ggplot(aes(diff, `CES 3.0 Percentile`, color = high_priority)) +
  geom_point() +
  scale_color_manual(values = c("grey", "red"))

ggplot() +
  geom_sf(data = sac) +
  geom_sf(data = gwl_ces, aes(color = high_priority)) +
  scale_color_manual(values = c("grey", "red"))
```

Inspecting these locations in closer detail over a satellite basemap may give us clues into what's happening here. 

```{r}
m2 <- filter(gwl_ces, high_priority == TRUE) %>% 
  select(diff, `CES 3.0 Percentile`) %>% 
  mapview(zcol = "diff", layer.name = "GWL <br>delcine (ft)")
m2
```

Compared to our previous mapview, which only showed areas with groundwater declines >= 25 feet over the historical record, the "high priority" most monitoring sites shown here that additionally have high CES scores appear to be located at or near the suburban fringe. 


## Learning more

EDA is the synthesis of every module we've covered so far, and many more that are beyond the scope of this course. As you learn more data transformation, visualization, and modeling skills, the depth of your EDA capabilities will increase. A good place to pick up general R knowledge and practice new skills is to walk through a textbook like [R for Data Science](https://r4ds.had.co.nz/), which will cover the basics and give you a good foundation on which to stand. 


## Communicating results

An EDA may generate tables, visualizations, and greater meaning that you've derived from the data. An excellent, R-centric way to share the results of your EDA is in an Rmd document, which is the topic of the [next module](11_intro_Rmarkdown.html).  
