{
  "articles": [
    {
      "path": "index.html",
      "title": "Welcome!",
      "description": "Increasing your efficiency with reproducible workflows in R\n",
      "author": [],
      "contents": "\n\n  .title{\n    display: none;\n  }\n\nWho is this course for?\nWhat makes an Intermediate R user? This course is most relevant and targeted at folks who:\nTook the Introductory R4WRDS course\nRegularly use R and want improve their efficiency and skill set\nHave a general understanding and proficiency in using {dplyr}, {ggplot2}, {sf}, and {rmarkdown}\nUnderstand (and use) general best practices for data science in R\nWhat will you learn?\nIn this course, we will move more quickly, assume familiarity with basic R skills, and also assume that the participant has experience with more complex workflows, operations, and code-bases. Each module in this course functions as a “stand-alone” lesson, and can be read linearly, or out of order according to your needs and interests. Each module doesn’t necessarily require familiarity with the previous module.\nThis course emphasizes:\nIntermediate scripting skills like iteration, functional programming, writing functions, and controlling project workflows for better reproducibility and efficiency.\nApproaches to working with more complex data structures like lists and timeseries data.\nThe fundamentals of building Shiny Apps.\nPulling water resources data from APIs.\nIntermediate mapmaking and spatial data processing.\nIntegrating version control in projects with git.\n\n\n\nFigure 1: Artwork by @allison_horst\n\n\n\n\nCourse Modules\nIn this course, we will:\nCheck/Update R/RStudio and Packages\nVersion Control with git\nProject Management and workflows\nInteractive visualization\nSimple shiny\nIteration with complex data\nParameterized reports\nAdvanced spatial R and mapmaking\nPulling data from APIs\n\n\nWhy R?\nR is an open-source language for statistical computing and a general purpose programming language. It is one of the primary languages used for data science, modeling, and visualization.\n\nWorkshop Overview\nWe will follow the SFS Code of Conduct throughout our workshop.\n\nSource content\nAll source materials for this website can be accessed at [final GH location, perhaps CAOpenWater/wrds].\n\nAttribution\nContent in these lessons has been modified and/or adapted from Data Carpentry: R for data analysis and visualization of Ecological Data, the USGS-R training curriculum here, the NCEAS Open Science for Synthesis workshop here, Mapping in R, and the wonderful text R for data science.\n\n\nNext module: Project Management\nsite last updated: 2021-04-29 12:34\n\n\n\n",
      "last_modified": "2021-04-29T12:34:55-07:00"
    },
    {
      "path": "m_project_management.html",
      "title": "Project Management & Data Organization",
      "description": "Approaches towards organization and efficiency.\n",
      "author": [],
      "contents": "\n\nContents\nFirst principles\n.RProfile\nGlobal (user-level) .Rprofile\nLocal (project-level) .Rprofile\nUsing .Rprofile\n\n.Renviron\nStrategies to organize projects/code\nAbstracting Functions from Code\n\nrenv\n\n\nLearning objectives\nImplement best practices for reproducible data science\nCreate and use an RStudio project (.RProj)\nUnderstand filepaths and {here}\nUnderstand how and when to modify .RProfile and .Renviron files\nApply strategies to organize functions and scripts\nUnderstand package environments and how to manage them with {renv}\n\nFirst principles\nThe first step in any data science project is to set up and maintain a clean, predictable development environment. As you accumulate raw data, write code, and generate results, things can get messy if you don’t stick to good programming naming and organization habits. In this module we’ll cover how to keep your projects organized and consistent, which ultimately will make projects more reproducible and keep your workflow more efficient and fun.\nA development environment is the set of tools you use to process data and the toolshed. R and packages are your tools, and an RProject is your toolshed.\n\nREVIEW\n\nAlthough this is an intermediate level course, we will revisit introductory material on “Project Management” because no matter your skill level in R, strategic project management remains fundamental. Subsequent modules in this course assume familiarity with {here}, .Rprojects, naming conventions, and general best practices.\n\n\n\nAfter reviewing core introductory topics, we will discuss .RProfile and .Renviron files and when to use them. To review core best practices we recommend particular familiarity with the following concepts:\nFilenaming\nRelative filepaths and the {here} package\nBest practices for project organization\n.RProfile\nIf you have user- or project-level code that needs to be run every time you start up R, customizing your .RProfile can streamline this operation.\nThe .RProfile file is an actual (hidden) file that is automatically sourced (run) as R code when you open an R session. A .RProfile file can live in the project root directory, or the user’s home directory, although only one .RProfile can be loaded per R session or RProject. If a project-level .Rprofile exists, it supersedes the user-level .Rprofile.\nYou can also “show hidden files” (instructions for Mac and PC) and edit .RProfile in a text editor. You can also do so in R with file.edit(\"~/.RProfile\").\nGlobal (user-level) .Rprofile\nThe easiest and most consistent way to edit your .RProfile file across operating systems is with the {usethis} package. Run usethis::edit_r_profile() to open your user-level (or global) .RProfile. This is the default .Rprofile that will be used for any and all projects unless you have a local (project-level) .Rprofile.\n\n\nusethis::edit_r_profile()\n\n\n\nLocal (project-level) .Rprofile\nWe can create or edit a local or project-level .RProfile with the scope argument inside the edit_r_profile function. Remember, a project-level .RProfile will supersede the global .Rprofile.\n\n\nusethis::edit_r_profile(scope = \"project\")\n\n\n\nUsing .Rprofile\nTo illustrate how .RProfile works, let’s do something cool and useless. We’ll write a short program that greets us with a random inspirational quote, and then we’ll put in .RProfile so it runs whenever we start up R.\nThe {cowsay} package is a fun way to print text animal art.\n\n\ncowsay::say(what = \"hello world!\", by = \"cow\")\n\n\n\n ----- \nhello world! \n ------ \n    \\   ^__^ \n     \\  (oo)\\ ________ \n        (__)\\         )\\ /\\ \n             ||------w|\n             ||      ||\n\nLet’s randomize the animal displayed and make the message it says one of the motivational quotes found at this Github repo, copy and paste the code into our .RProfile, and restart R.\n\n\nlibrary(cowsay) # animals!\nlibrary(glue)   # pasting things together\n\n# get vector of all animals\nanimals <- names(cowsay::animals)\n\n# get pieces to make link\nrepo <- \"JakubPetriska/060958fd744ca34f099e947cd080b540\"\ncsv <- \"raw/963b5a9355f04741239407320ac973a6096cd7b6/quotes.csv\"\n\n# get dataframe of inspirational quotes\nquotes  <- readr::read_csv(glue(\"https://gist.githubusercontent.com/{repo}/{csv}\"))  \n\n# make full quote\nquotes$full_quote  <- glue(\"{quotes$Quote} - {quotes$Author}\")\n\n# now use it!\ncowsay::say(sample(quotes$full_quote, 1), by = sample(animals, 1))\n\n\n\n ------------- \nIn separateness lies the world's great misery, in compassion lies the world's true strength. - Buddha \n -------------- \n              \\   \n               \\  \n                \\\n        __.--'\\     \\.__./     /'--.__\n    _.-'       '.__.'    '.__.'       '-._\n  .'                                      '.\n /                                          \\\n|                                            |\n|                                            |\n \\         .---.              .---.         /\n  '._    .'     '.''.    .''.'     '.    _.'\n     '-./            \\  /           \\.-'\n                      ''mrf\n\nrm(animals, quotes) # remove the objects we just created\n\n\n\n.Renviron\nSometimes you need to store sensitive information, like API Keys, Database passwords, data storage paths, or general variables used across all scripts. We don’t want to accidentally share these information, accidentally push them to Github, or copy and paste them over and over again from script to script. We also might want to build a codebase that relies on a few variables that another user can set in their own system in a way that works for them. Environmental variables are the way to address all of these concerns.\nEnvironmental variables are objects that store character strings. They are accessible from within R upon startup. To view all environmental variables, use Sys.getenv(). You can also pull out one environmental variable at a time by passing in its name, for instance:\n\n\nSys.getenv(\"USER\")\n\n\n[1] \"richpauloo\"\n\nYou can set your own environmental variables which are stored in another hidden file called .Renviron (this is the Python analog of .env). Keep in mind, .Renviron files typically contain lists of environmental variables that look similar to R code but it is actually not running R code…so don’t put R code in your .Renviron file! If we need to run R code when starting up R, we use .RProfile.\nTo illustrate the use of .Renviron, we run usethis::edit_r_environ(), add the environmental variable ANIMAL = \"cat\", save, and restart R.\n\n\nusethis::edit_r_environ()\n\n\n\nWe can access our environmental variable as follows (remember you need to restart R for changes to take effect, try Session > Restart R):\n\n\nSys.getenv(\"ANIMAL\")\n\n\n\nWe can use our environmental variable, for instance, in a function.\n\n\ninspire_me <- function(animal){\n\n  # get pieces to make link\n  repo <- \"JakubPetriska/060958fd744ca34f099e947cd080b540\"\n  csv  <- \"raw/963b5a9355f04741239407320ac973a6096cd7b6/quotes.csv\"\n  \n  # silently read dataframe\n  suppressMessages(\n    quotes  <- readr::read_csv(\n      glue::glue(\"https://gist.githubusercontent.com/{repo}/{csv}\")\n    )  \n  )\n  \n  # paste together the full quote\n  quotes$full_quote  <- paste0(quotes$Quote, \" -\", quotes$Author)\n  \n  # make a user-specified animal say the quote\n  cowsay::say(sample(quotes$full_quote, 1), by = animal)\n\n}\n\n# have the environmental variable say a quote\ninspire_me(Sys.getenv(\"ANIMAL\"))\n\n\n\nAlthough it may not appear powerful in this trivial example, when a project grows substantially large and complex, or when managing multiple sensitive passwords and access tokens, environmental variables are a standard approach that are widely used.\nImportant note, both these files .Renviron and .Rprofile need to end with a blank newline at the end. If this isn’t present, the last line of the file is ignored, and there isn’t a message or error associated with this. The usethis functions typically take care of this for you, but be aware of it just in case!\n\nPause and think\n\nIn the example function above, we might notice that reading in a url from a csv every time we run inspire_me() is a lot of unnecessary overhead. Where else might we be able to read that csv in automatically when R starts up, so that it’s available for our inspire_me() function, and that we only need to read it once?\n\n\n\nClick for Answers!\n\nWe can move read step of the csv into a project-level RProfile, so it’s available to the project where we need this csv, but not to any general R session we may open outside of the project.\n.RProfile\n\n\n# get pieces to make link\nrepo <- \"JakubPetriska/060958fd744ca34f099e947cd080b540\"\ncsv  <- \"raw/963b5a9355f04741239407320ac973a6096cd7b6/quotes.csv\"\n\n# silently read dataframe\nsuppressMessages(\n  quotes  <- readr::read_csv(\n    glue::glue(\"https://gist.githubusercontent.com/{repo}/{csv}\")\n  )  \n)\n\n# paste together the full quote\nquotes$full_quote  <- paste0(quotes$Quote, \" -\", quotes$Author)\n\n\n\nModified function\n\n\ninspire_me <- function(animal){\n\n  # make a user-specified animal say the quote\n  cowsay::say(sample(quotes$full_quote, 1), by = animal)\n\n}\n\n\n\n\nStrategies to organize projects/code\nBest practices for writing code across languages typically recommend package imports and function definitions at the top of a script, followed by code. For example, a script may look like this:\n\n\n# import packages\nlibrary(package_1)\nlibrary(package_2)\n\n# define functions\nmy_first_function <- function(){\n  print(\"hello\")\n}\n\nmy_second_function <- function(){\n  print(\"world\")\n}\n\n# run code/functions\nmy_first_function()\nmy_second_function()\n\n\n\nThese approaches work well when scripts are relatively simple, but as a project grows large and complex, it’s best practice to move functions into another script or set of scripts, and break up your workflow into discrete steps.\nFor instance, although the inspire_me() function above is relatively simple, we can pretend that the read, transform, and print steps carried out in the function were themselves long functions in part of a much more complex, real-world workflow. Imagine we created a script called functions.R that contained the following code. Don’t worry if you haven’t seen purrr::walk() before. We’ll cover this in a later module on iteration, and all you need to know about it now is that it “walks” over each input and applies a function. In this case, we apply the require() function to a vector of package names to load them.\n\nNotice that all functions start with f_. This prefix makes it easy to read in a script and takes advantage of auto-complete.\n\n\n# list packages in a vector and load them all\npkgs <- c(\"readr\", \"cowsay\")\npurrr::walk(pkgs, require, character.only = TRUE)\n\n# read quotes from a url\nf_read_data <- function(url){\n  suppressMessages(\n    quotes  <- read_csv(url)  \n  )\n  return(quotes)\n}\n\n# paste the quote to the author\nf_preprocess_data <- function(d){\n  d$full_quote  <- paste0(d$Quote, \" -\", d$Author)\n  return(d)\n}\n\n# print a random animal and a random quote\nf_inspire_me <- function(d){\n  animals <- names(animals)\n  say(sample(d$full_quote, 1), by = sample(animals, 1))\n}\n\n\n\nWe can call this script using source() to load or import these functions into our environment where they are available for use, just as we load a library.\n\n\nsource(here(\"functions.R\"))\n\n\n\nAbstracting Functions from Code\nHowever, this is hardly a satisfying solution because in a real project, our pretend functions above may grow quite large, and we will likely add more and more functions. Eventually, a single script may hold them all, and something like functions.R may become many hundreds of lines long, making it difficult to sift through, debug, or add new lines of code. A better organizational approach which makes things easier to maintain over time is to move all our functions to a directory /functions, and store them all as separate files named after their function name:\n\nA good rule of thumb to follow is to try and keep scripts less than 150 lines in length. When scripts approach this length, they become difficult to keep track of, and there were likely missed opportunities to refactor the script into separate functions and modules.\nSave as /functions/f_read_data.R\n\n\n# read quotes from a url\nf_read_data <- function(url){\n  suppressMessages(\n    quotes  <- read_csv(url)\n  )\n  return(quotes)\n}\n\n\n\nSave as /functions/f_preprocess_data.R\n\n\n# paste the quote to the author\nf_preprocess_data <- function(d){\n  d$full_quote  <- paste0(d$Quote, \" -\", d$Author)\n  return(d)\n}\n\n\n\nSave as /functions/f_inspire_me.R\n\n\n# print a random animal and a random quote\nf_inspire_me <- function(d){\n  animals <- names(animals)\n  say(sample(d$full_quote, 1), by = sample(animals, 1))\n}\n\n\n\nThe functions folder in the root project directory should now look like this:\n\n\n\nNow in our /code directory, we create a script, 01_control.R to source our functions and use them. Be sure to restart R to clear your environment before sourcing this control script so we know we are working from a clean slate.\nSave as /code/01_control.R and run.\n\n\n# packages needed for this script\npkgs <- c(\"readr\", \"cowsay\", \"here\", \"tidyverse\", \"glue\")\npurrr::walk(pkgs, require, character.only = TRUE)\n\n# silently source all functions using the purrr::walk function\nwalk(list.files(here(\"functions\"), full.names = TRUE), ~source(.x))\n\n# define the url where quotes are located\n# get pieces to make link\nrepo <- \"JakubPetriska/060958fd744ca34f099e947cd080b540\"\ncsv <- \"raw/963b5a9355f04741239407320ac973a6096cd7b6/quotes.csv\"\nurl <- glue(\"https://gist.githubusercontent.com/{repo}/{csv}\")  \n\n# use all of our functions\nf_read_data(url) %>% \n  f_preprocess_data() %>% \n  f_inspire_me()\n\n\n\n ----- \nWe know the truth, not only by the reason, but by the heart. -Blaise Pascal \n ------ \n    \\   \n     \\\n     .-.\n    (o o)\n    | O \\\n     \\   \\\n      `~~~' [nosig]\n  \n\nsource() is the key to chaining together many scripts. In the example above, we were able to abstract functions into a separate folder which makes keeping track of them much easier than if they cluttered our control script.\n\nIt’s also a good rule of thumb to keep each line of code less than 75 characters long to ease readability.\n\nLearn more\n\nSeparating all functions into standalone scripts is not a revolutionary idea – in fact, this is precisely how R packages are written! For example, see the {dplyr} github repo’s /R folder which contains all dplyr functions in one directory. When you call library(dplyr) you’re essentially sourcing all of these functions into your environment.\n\n\nIf project management and reproducible data pipelines are interesting to you, check out the {targets} R package. A similar framework for Shiny Apps exists called {golem}, which also includes {usethis}-like commands that streamline common chores in Shiny App development.\n\n\nrenv\nWe use {here} because we expect that whoever else opens your code on their machine is likely to have a different project root path, and {here} ensures your code is portable between different computers with different root project paths (e.g., ~/Documents/Github/myproject versus C:\\Users\\louis\\Documents\\myproject).\nDevelopment environments are similar. When we work in R – or any programming language for that matter – we use a snapshot of package versions based on when we downloaded and installed them [e.g. with install.packages()]. You can check the version of the installed packages loaded into your current environment with sessionInfo().\n\n\nsessionInfo()\n\n\nR version 4.0.2 (2020-06-22)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.4     purrr_0.3.4    \n [5] tidyr_1.1.2     tibble_3.1.0    tidyverse_1.3.0 here_0.1       \n [9] readr_1.4.0     glue_1.4.2      cowsay_0.8.0    knitr_1.30     \n[13] ggplot2_3.3.3  \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.1.0  xfun_0.22         haven_2.3.1      \n [4] colorspace_2.0-0  vctrs_0.3.7       generics_0.1.0   \n [7] htmltools_0.5.1.1 usethis_2.0.0     yaml_2.2.1       \n[10] utf8_1.2.1        rlang_0.4.10      gridtext_0.1.4   \n[13] pillar_1.5.1      withr_2.4.1       DBI_1.1.1        \n[16] dbplyr_2.1.0      readxl_1.3.1      modelr_0.1.8     \n[19] fortunes_1.5-4    lifecycle_1.0.0   cellranger_1.1.0 \n[22] munsell_0.5.0     gtable_0.3.0      rvest_0.3.6      \n[25] evaluate_0.14     curl_4.3          fansi_0.4.2      \n[28] broom_0.7.0       Rcpp_1.0.6        scales_1.1.1     \n[31] backports_1.1.10  jsonlite_1.7.2    fs_1.5.0         \n[34] rmsfact_0.0.3     distill_1.2       hms_1.0.0        \n[37] png_0.1-7         digest_0.6.27     stringi_1.5.3    \n[40] grid_4.0.2        rprojroot_1.3-2   cli_2.4.0        \n[43] tools_4.0.2       magrittr_2.0.1    crayon_1.4.1     \n[46] pkgconfig_2.0.3   downlit_0.2.1     ellipsis_0.3.1   \n[49] xml2_1.3.2        reprex_0.3.0      lubridate_1.7.9.2\n[52] httr_1.4.2        assertthat_0.2.1  rmarkdown_2.7    \n[55] rstudioapi_0.11   R6_2.5.0          ggtext_0.1.1     \n[58] compiler_4.0.2   \n\nThe version number is the string of numbers listed after a package name and underscore.\nSimilarly, you can use installed.packages() to view information on all of your installed packages.\nWhen packages change between versions, changes are typically designed to fix bugs or improve performance, but sometimes, they can break code. Thus, collaborative work on a project may be challenged by people working on the same code but with different versions of packages.\n\nEven the version of R itself changes, although base R changes very slowly and the R Core Team tries to make new versions of R backwards-compatible to not break scripts written before potentially breaking changes.\nThe solution to this problem is for everyone to use the same versions of packages (and R), which is to say that collaborators should use the same development environment. This is a common concept across programming languages.\n{renv} manages your package environment and makes it easy to share it with others by creating and curating a “lock” file (renv.lock) in the root project directory. When starting a project, create the file with renv::init(), install packages as you go along, and update the lockfile with renv::snapshot(). When a collaborator opens your project (for example, after cloning it from Github), all they need to do is open the .RProj file and {renv} will automatically set up the development environment captured in the lock file.\n\nThe renv.lock file is a JSON file with information on the version of R and the versions of all packages used by the project.\nIf you find yourself needing to share important analyses, perhaps that run on a production server, you should look into {renv}. For most day-to-day data science that you don’t plan on sharing or working collaboratively on, it may be unnecessary.\n\n\nPrevious module: Introduction Next module: Git\n\n\n\n",
      "last_modified": "2021-04-29T12:24:38-07:00"
    }
  ],
  "collections": []
}
