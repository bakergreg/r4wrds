{
  "articles": [
    {
      "path": "index.html",
      "title": "Welcome!",
      "description": "Increasing your efficiency with reproducible workflows in R\n",
      "author": [],
      "contents": "\n\n  .title{\n    display: none;\n  }\n\nWho is this course for?\nWhat makes an Intermediate R user? This course is most relevant and targeted at folks who:\nTook the Introductory R4WRDS course\nRegularly use R and want improve their efficiency and skill set\nHave a general understanding and proficiency in using {dplyr}, {ggplot2}, {sf}, and {rmarkdown}\nUnderstand (and use) general best practices for data science in R\nWhat will you learn?\nIn this course, we will move more quickly, assume familiarity with basic R skills, and also assume that the participant has experience with more complex workflows, operations, and code-bases. Each module in this course functions as a “stand-alone” lesson, and can be read linearly, or out of order according to your needs and interests. Each module doesn’t necessarily require familiarity with the previous module.\nThis course emphasizes:\nIntermediate scripting skills like iteration, functional programming, writing functions, and controlling project workflows for better reproducibility and efficiency.\nApproaches to working with more complex data structures like lists and timeseries data.\nThe fundamentals of building Shiny Apps.\nPulling water resources data from APIs.\nIntermediate mapmaking and spatial data processing.\nIntegrating version control in projects with git.\n\n\n\nFigure 1: Artwork by @allison_horst\n\n\n\n\nCourse Modules\nIn this course, we will:\nCheck/Update R/RStudio and Packages\nVersion Control with git\nProject Management and workflows\nInteractive visualization\nSimple shiny\nIteration with complex data\nParameterized reports\nAdvanced spatial R and mapmaking\nPulling data from APIs\n\n\nWhy R?\nR is an open-source language for statistical computing and a general purpose programming language. It is one of the primary languages used for data science, modeling, and visualization.\n\nWorkshop Overview\nWe will follow the SFS Code of Conduct throughout our workshop.\n\nSource content\nAll source materials for this website can be accessed at [final GH location, perhaps CAOpenWater/wrds].\n\nAttribution\nContent in these lessons has been modified and/or adapted from Data Carpentry: R for data analysis and visualization of Ecological Data, the USGS-R training curriculum here, the NCEAS Open Science for Synthesis workshop here, Mapping in R, and the wonderful text R for data science.\n\n\nNext module: Project Management\nsite last updated: 2021-04-29 12:34\n\n\n\n",
      "last_modified": "2021-05-03T19:20:35-07:00"
    },
    {
      "path": "m_project_management.html",
      "title": "Project Management & Data Organization",
      "description": "Approaches towards organization and efficiency.\n",
      "author": [],
      "contents": "\n\nContents\nFirst principles\n.RProfile\nGlobal (user-level) .Rprofile\nLocal (project-level) .Rprofile\nUsing .Rprofile\n\n.Renviron\nStrategies to organize projects/code\nAbstracting Functions from Code\n\n{renv}\n\n\nLearning objectives\nImplement best practices for reproducible data science\nCreate and use an RStudio project (.RProj)\nUnderstand filepaths and {here}\nUnderstand how and when to modify .RProfile and .Renviron files\nApply strategies to organize functions and scripts\nUnderstand package environments and how to manage them with {renv}\n\nFirst principles\n\n\n\nFigure 1: What to avoid building (Source: https://xkcd.com/2054/).\n\n\n\nThe first step in any data science project is to set up and maintain a clean, predictable development environment. As you accumulate raw data, write code, and generate results, things can get messy if you don’t stick to good programming naming and organization habits. In this module we’ll cover how to keep your projects organized and consistent, which will make your projects more reproducible, keep your workflows efficient, firm up your code to stand the test of time, and give your code structure so it’s easy to maintain when things break or you need to revisit it down the line.\nA development environment is the set of tools you use to process data and the toolshed. R and packages are your tools, and an RProject is your toolshed.\n\nREVIEW\n\nAlthough this is an intermediate level course, we will revisit introductory material on “Project Management” because no matter your skill level in R, strategic project management remains fundamental. Subsequent modules in this course assume familiarity with {here}, .Rprojects, naming conventions, and general best practices.\n\n\n\nAfter reviewing core introductory topics, we will discuss .RProfile and .Renviron files and when to use them. To review core best practices we recommend particular familiarity with the following concepts:\nFilenaming\nRelative filepaths and the {here} package\nBest practices for project organization\n.RProfile\nIf you have user- or project-level code that needs to be run every time you start up R, customizing your .RProfile can streamline this operation.\nThe .RProfile file is an actual (hidden) file that is automatically sourced (run) as R code when you open an R session. A .RProfile file can live in the project root directory, or the user’s home directory, although only one .RProfile can be loaded per R session or RProject. If a project-level .Rprofile exists, it supersedes the user-level .Rprofile.\nYou can also “show hidden files” (instructions for Mac and PC) and edit .RProfile in a text editor. You can also do so in R with file.edit(\"~/.RProfile\").\nGlobal (user-level) .Rprofile\nThe easiest and most consistent way to edit your .RProfile file across operating systems is with the {usethis} package. Run usethis::edit_r_profile() to open your user-level (or global) .RProfile. This is the default .Rprofile that will be used for any and all projects unless you have a local (project-level) .Rprofile.\n\n\nusethis::edit_r_profile()\n\n\n\nLocal (project-level) .Rprofile\nWe can create or edit a local or project-level .RProfile with the scope argument inside the edit_r_profile function. Remember, a project-level .RProfile will supersede the global .Rprofile.\n\n\nusethis::edit_r_profile(scope = \"project\")\n\n\n\nUsing .Rprofile\nTo illustrate how .RProfile works, let’s do something cool and useless. We’ll write a short program that greets us with a random inspirational quote, and then we’ll put in .RProfile so it runs whenever we start up R.\nThe {cowsay} package is a fun way to print text animal art.\n\n\ncowsay::say(what = \"hello world!\", by = \"cow\")\n\n\n\n ----- \nhello world! \n ------ \n    \\   ^__^ \n     \\  (oo)\\ ________ \n        (__)\\         )\\ /\\ \n             ||------w|\n             ||      ||\n\nLet’s randomize the animal displayed and make the message it says one of the motivational quotes found at this Github repo, copy and paste the code into our .RProfile, and restart R.\n\n\nlibrary(cowsay) # animals!\nlibrary(glue)   # pasting things together\n\n# get vector of all animals\nanimals <- names(cowsay::animals)\n\n# get pieces to make link\nrepo <- \"JakubPetriska/060958fd744ca34f099e947cd080b540\"\ncsv <- \"raw/963b5a9355f04741239407320ac973a6096cd7b6/quotes.csv\"\n\n# get dataframe of inspirational quotes\nquotes  <- readr::read_csv(glue(\"https://gist.githubusercontent.com/{repo}/{csv}\"))  \n\n# make full quote\nquotes$full_quote  <- glue(\"{quotes$Quote} - {quotes$Author}\")\n\n# now use it!\ncowsay::say(sample(quotes$full_quote, 1), by = sample(animals, 1))\n\n\n\n ----- \nBe like the flower, turn your face to the sun. - Kahlil Gibran \n ------ \n    \\   \n     \\\n                \\`*-.\n                 )  _`-.\n                .  : `. .\n                : _   '  \\\n                ; *` _.   `*-._\n                `-.-'          `-.\n                  ;       `       `.\n                  :.       .       \\\n                  .\\  .   :   .-'   .\n                  '  `+.;  ;  '      :\n                  :  '  |    ;       ;-.\n                  ; '   : :`-:     _.`* ;\n               .*' /  .*' ; .*`- +'  `*'\n     [bug]     `*-*   `*-*  `*-*'\n    \n\nrm(animals, quotes) # remove the objects we just created\n\n\n\n.Renviron\nSometimes you need to store sensitive information, like API Keys, Database passwords, data storage paths, or general variables used across all scripts. We don’t want to accidentally share these information, accidentally push them to Github, or copy and paste them over and over again from script to script. We also might want to build a codebase that relies on a few variables that another user can set in their own system in a way that works for them. Environmental variables are the way to address all of these concerns.\nEnvironmental variables are objects that store character strings. They are accessible from within R upon startup. To view all environmental variables, use Sys.getenv(). You can also pull out one environmental variable at a time by passing in its name, for instance:\n\n\nSys.getenv(\"USER\")\n\n\n[1] \"richpauloo\"\n\nYou can set your own environmental variables which are stored in another hidden file called .Renviron (this is the Python analog of .env). Keep in mind, .Renviron files typically contain lists of environmental variables that look similar to R code but it is actually not running R code…so don’t put R code in your .Renviron file! If we need to run R code when starting up R, we use .RProfile.\nTo illustrate the use of .Renviron, we run usethis::edit_r_environ(), add the environmental variable ANIMAL = \"cat\", save, and restart R.\n\n\nusethis::edit_r_environ()\n\n\n\nWe can access our environmental variable as follows (remember you need to restart R for changes to take effect, try Session > Restart R):\n\n\nSys.getenv(\"ANIMAL\")\n\n\n\nWe can use our environmental variable, for instance, in a function.\n\n\ninspire_me <- function(animal){\n\n  # get pieces to make link\n  repo <- \"JakubPetriska/060958fd744ca34f099e947cd080b540\"\n  csv  <- \"raw/963b5a9355f04741239407320ac973a6096cd7b6/quotes.csv\"\n  \n  # silently read dataframe\n  suppressMessages(\n    quotes  <- readr::read_csv(\n      glue::glue(\"https://gist.githubusercontent.com/{repo}/{csv}\")\n    )  \n  )\n  \n  # paste together the full quote\n  quotes$full_quote  <- paste0(quotes$Quote, \" -\", quotes$Author)\n  \n  # make a user-specified animal say the quote\n  cowsay::say(sample(quotes$full_quote, 1), by = animal)\n\n}\n\n# have the environmental variable say a quote\ninspire_me(Sys.getenv(\"ANIMAL\"))\n\n\n\nAlthough it may not appear powerful in this trivial example, when a project grows substantially large and complex, or when managing multiple sensitive passwords and access tokens, environmental variables are a standard approach that are widely used.\nImportant note, both these files .Renviron and .Rprofile need to end with a blank newline at the end. If this isn’t present, the last line of the file is ignored, and there isn’t a message or error associated with this. The usethis functions typically take care of this for you, but be aware of it just in case!\n\nPause and think\n\nIn the example function above, we might notice that reading in a url from a csv every time we run inspire_me() is a lot of unnecessary overhead. Where else might we be able to read that csv in automatically when R starts up, so that it’s available for our inspire_me() function, and that we only need to read it once?\n\n\n\nClick for Answers!\n\nWe can move read step of the csv into a project-level RProfile, so it’s available to the project where we need this csv, but not to any general R session we may open outside of the project.\n.RProfile\n\n\n# get pieces to make link\nrepo <- \"JakubPetriska/060958fd744ca34f099e947cd080b540\"\ncsv  <- \"raw/963b5a9355f04741239407320ac973a6096cd7b6/quotes.csv\"\n\n# silently read dataframe\nsuppressMessages(\n  quotes  <- readr::read_csv(\n    glue::glue(\"https://gist.githubusercontent.com/{repo}/{csv}\")\n  )  \n)\n\n# paste together the full quote\nquotes$full_quote  <- paste0(quotes$Quote, \" -\", quotes$Author)\n\n\n\nModified function\n\n\ninspire_me <- function(animal){\n\n  # make a user-specified animal say the quote\n  cowsay::say(sample(quotes$full_quote, 1), by = animal)\n\n}\n\n\n\n\nStrategies to organize projects/code\nBest practices for writing code across languages typically recommend package imports and function definitions at the top of a script, followed by code. For example, a script may look like this:\n\n\n# import packages\nlibrary(package_1)\nlibrary(package_2)\n\n# define functions\nmy_first_function <- function(){\n  print(\"hello\")\n}\n\nmy_second_function <- function(){\n  print(\"world\")\n}\n\n# run code/functions\nmy_first_function()\nmy_second_function()\n\n\n\nThese approaches work well when scripts are relatively simple, but as a project grows large and complex, it’s best practice to move functions into another script or set of scripts, and break up your workflow into discrete steps.\nFor instance, although the inspire_me() function above is relatively simple, we can pretend that the read, transform, and print steps carried out in the function were themselves long functions in part of a much more complex, real-world workflow. Imagine we created a script called functions.R that contained the following code. Don’t worry if you haven’t seen purrr::walk() before. We’ll cover this in a later module on iteration, and all you need to know about it now is that it “walks” over each input and applies a function. In this case, we apply the require() function to a vector of package names to load them.\n\nNotice that all functions start with f_. This prefix makes it easy to read in a script and takes advantage of auto-complete.\n\n\n# list packages in a vector and load them all\npkgs <- c(\"readr\", \"cowsay\")\npurrr::walk(pkgs, require, character.only = TRUE)\n\n# read quotes from a url\nf_read_data <- function(url){\n  suppressMessages(\n    quotes  <- read_csv(url)  \n  )\n  return(quotes)\n}\n\n# paste the quote to the author\nf_preprocess_data <- function(d){\n  d$full_quote  <- paste0(d$Quote, \" -\", d$Author)\n  return(d)\n}\n\n# print a random animal and a random quote\nf_inspire_me <- function(d){\n  animals <- names(animals)\n  say(sample(d$full_quote, 1), by = sample(animals, 1))\n}\n\n\n\nWe can call this script using source() to load or import these functions into our environment where they are available for use, just as we load a library.\n\n\nsource(here(\"functions.R\"))\n\n\n\nAbstracting Functions from Code\nHowever, this is hardly a satisfying solution because in a real project, our pretend functions above may grow quite large, and we will likely add more and more functions. Eventually, a single script may hold them all, and something like functions.R may become many hundreds of lines long, making it difficult to sift through, debug, or add new lines of code. A better organizational approach which makes things easier to maintain over time is to move all our functions to a directory /functions, and store them all as separate files named after their function name:\n\nA good rule of thumb to follow is to try and keep scripts less than 150 lines in length. When scripts approach this length, they become difficult to keep track of, and there were likely missed opportunities to refactor the script into separate functions and modules.\nSave as /functions/f_read_data.R\n\n\n# read quotes from a url\nf_read_data <- function(url){\n  suppressMessages(\n    quotes  <- read_csv(url)\n  )\n  return(quotes)\n}\n\n\n\nSave as /functions/f_preprocess_data.R\n\n\n# paste the quote to the author\nf_preprocess_data <- function(d){\n  d$full_quote  <- paste0(d$Quote, \" -\", d$Author)\n  return(d)\n}\n\n\n\nSave as /functions/f_inspire_me.R\n\n\n# print a random animal and a random quote\nf_inspire_me <- function(d){\n  animals <- names(animals)\n  say(sample(d$full_quote, 1), by = sample(animals, 1))\n}\n\n\n\nThe functions folder in the root project directory should now look like this:\n\n\n\nNow in our /code directory, we create a script, 01_control.R to source our functions and use them. Be sure to restart R to clear your environment before sourcing this control script so we know we are working from a clean slate.\nSave as /code/01_control.R and run.\n\n\n# packages needed for this script\npkgs <- c(\"readr\", \"cowsay\", \"here\", \"tidyverse\", \"glue\")\npurrr::walk(pkgs, require, character.only = TRUE)\n\n# silently source all functions using the purrr::walk function\nwalk(list.files(here(\"functions\"), full.names = TRUE), ~source(.x))\n\n# define the url where quotes are located\n# get pieces to make link\nrepo <- \"JakubPetriska/060958fd744ca34f099e947cd080b540\"\ncsv <- \"raw/963b5a9355f04741239407320ac973a6096cd7b6/quotes.csv\"\nurl <- glue(\"https://gist.githubusercontent.com/{repo}/{csv}\")  \n\n# use all of our functions\nf_read_data(url) %>% \n  f_preprocess_data() %>% \n  f_inspire_me()\n\n\n\n -------------- \nBetter than a thousand hollow words is one word that brings peace. -Buddha \n --------------\n    \\\n      \\\n        \\\n        /\\_/\\         _\n       /``   \\       / )\n       |n n   |__   ( (\n      =(Y =.‛`   `\\  \\ \\\n      {`\"`        \\  ) )\n      {       /    |/ /\n       \\\\   ,(     / /\n        ) ) /-‛\\  ,_.‛\n  jgs  (,(,/ ((,,/\n  \n\nsource() is the key to chaining together many scripts. In the example above, we were able to abstract functions into a separate folder which makes keeping track of them much easier than if they cluttered our control script.\n\nIt’s also a good rule of thumb to keep each line of code less than 75 characters long to ease readability.\n\nLearn more\n\nSeparating all functions into standalone scripts is not a revolutionary idea – in fact, this is precisely how R packages are written! For example, see the {dplyr} github repo’s /R folder which contains all dplyr functions in one directory. When you call library(dplyr) you’re essentially sourcing all of these functions into your environment.\n\n\nIf project management and reproducible data pipelines are interesting to you, check out the {targets} R package. A similar framework for Shiny Apps exists called {golem}, which also includes {usethis}-like commands that streamline common chores in Shiny App development.\n\n\n{renv}\nWe use {here} because we expect that whoever else opens your code on their machine is likely to have a different project root path, and {here} ensures your code is portable between different computers with different root project paths (e.g., ~/Documents/Github/myproject versus C:\\Users\\louis\\Documents\\myproject).\nDevelopment environments are similar. When we work in R – or any programming language for that matter – we use a snapshot of package versions based on when we downloaded and installed them [e.g. with install.packages()]. You can check the version of the installed packages loaded into your current environment with sessionInfo().\n\n\nsessionInfo()\n\n\nR version 4.0.2 (2020-06-22)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.4     purrr_0.3.4    \n [5] tidyr_1.1.2     tibble_3.1.0    tidyverse_1.3.0 here_0.1       \n [9] readr_1.4.0     glue_1.4.2      cowsay_0.8.0    knitr_1.30     \n[13] ggplot2_3.3.3  \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.1.0  xfun_0.22         haven_2.3.1      \n [4] colorspace_2.0-0  vctrs_0.3.7       generics_0.1.0   \n [7] htmltools_0.5.1.1 usethis_2.0.0     yaml_2.2.1       \n[10] utf8_1.2.1        rlang_0.4.10      gridtext_0.1.4   \n[13] pillar_1.5.1      withr_2.4.1       DBI_1.1.1        \n[16] dbplyr_2.1.0      readxl_1.3.1      modelr_0.1.8     \n[19] fortunes_1.5-4    lifecycle_1.0.0   cellranger_1.1.0 \n[22] munsell_0.5.0     gtable_0.3.0      rvest_0.3.6      \n[25] evaluate_0.14     curl_4.3          fansi_0.4.2      \n[28] highr_0.8         broom_0.7.0       Rcpp_1.0.6       \n[31] scales_1.1.1      backports_1.1.10  jsonlite_1.7.2   \n[34] fs_1.5.0          rmsfact_0.0.3     distill_1.2      \n[37] hms_1.0.0         png_0.1-7         digest_0.6.27    \n[40] stringi_1.5.3     grid_4.0.2        rprojroot_1.3-2  \n[43] cli_2.4.0         tools_4.0.2       magrittr_2.0.1   \n[46] crayon_1.4.1      pkgconfig_2.0.3   downlit_0.2.1    \n[49] ellipsis_0.3.1    xml2_1.3.2        reprex_0.3.0     \n[52] lubridate_1.7.9.2 httr_1.4.2        assertthat_0.2.1 \n[55] rmarkdown_2.7     rstudioapi_0.11   R6_2.5.0         \n[58] ggtext_0.1.1      compiler_4.0.2   \n\nThe version number is the string of numbers listed after a package name and underscore.\nSimilarly, you can use installed.packages() to view information on all of your installed packages.\nWhen packages change between versions, changes are typically designed to fix bugs or improve performance, but sometimes, they can break code. Thus, collaborative work on a project may be challenged by people working on the same code but with different versions of packages.\n\nEven the version of R itself changes, although base R changes very slowly and the R Core Team tries to make new versions of R backwards-compatible to not break scripts written before potentially breaking changes.\nThe solution to this problem is for everyone to use the same versions of packages (and R), which is to say that collaborators should use the same development environment. This is a common concept across programming languages.\n{renv} manages your package environment and makes it easy to share it with others by creating and curating a “lock” file (renv.lock) in the root project directory. When starting a project, create the file with renv::init(), install packages as you go along, and update the lockfile with renv::snapshot(). When a collaborator opens your project (for example, after cloning it from Github), all they need to do is open the .RProj file and {renv} will automatically set up the development environment captured in the lock file.\n\nThe renv.lock file is a JSON file with information on the version of R and the versions of all packages used by the project.\nIf you find yourself needing to share important analyses, perhaps that run on a production server, you should look into {renv}. For most day-to-day data science that you don’t plan on sharing or working collaboratively on, it may be unnecessary.\n\n\nPrevious module: Introduction Next module: Git\n\n\n\n",
      "last_modified": "2021-05-06T16:47:28-07:00"
    },
    {
      "path": "m_simple_shiny.html",
      "title": "Simple Shiny",
      "description": "How to create interactive dashboards with R\n",
      "author": [],
      "contents": "\n\nContents\nWhat is a Shiny App and Why is it useful?\nCase Study: Sacramento county groundwater elevation\n\nBasic Shiny App Structure\nCreating a Shiny App\nui (user interface)\nserver\nother files\n\nShare and deploy a Shiny App\nExtending Shiny\nAdditional Resources\n\n\n\nLearning objectives\nUnderstand what a Shiny App is and why you might need to build one\nUnderstand the basic structure of a Shiny App and common hiccups\nDiscuss approaches to extend your Shiny skills\n\nWhat is a Shiny App and Why is it useful?\nAccording to the Mastering Shiny book:\n\nShiny is a framework for creating web applications using R code. It is designed primarily with data scientists in mind, and to that end, you can create pretty complicated Shiny apps with no knowledge of HTML, CSS, or JavaScript.\n\nShiny Apps are made using the {shiny} package.\nBecause they extend R-based analyses, Shiny Apps have as many diverse niches and uses as the the R community itself, and it’s likely that you have come across a Shiny App in the wild before.\nShiny Apps allow for a wide range of customizability, and allow R users to wrap their code and datasets in an additional layer of interactivity in order to make insights, visualizations, data download, and more available to non-R users.\nNow that we know what a Shiny App is, a fundamental question that we need to answer is “when and why should I build a Shiny App?” Generally, you should create a Shiny App when you want to make results and/or data available to others and when the dataset you wish to explore is complex enough to warrant a Shiny App. To provide a specific example, let’s examine a case study.\nCase Study: Sacramento county groundwater elevation\nImagine you’re analyzing groundwater levels across California1 and want to assess groundwater elevation trends over time in Sacramento County. You may begin with an EDA to filter the data to Sacramento County, clean the data, and make some exploratory plots.\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(sf)\n\n# read groundwater level data pre-filtered to Sacramento county\ngwl <- read_csv(here(\"data\", \"gwl\", \"gwl_sac.csv\")) %>% \n  st_as_sf(coords = c(\"LONGITUDE\",\"LATITUDE\"), crs = 4269)\n\n# read sacramento county shapefile and reproject\nsac <- st_read(here(\"data\", \"shp\", \"sac\", \"sac_county.shp\")) %>% \n  st_transform(4269)\n\n\nReading layer `sac_county' from data source `/Users/richpauloo/Documents/GitHub/WRDS_intro/intermediate/data/shp/sac/sac_county.shp' using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 9 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -13565710 ymin: 4582007 xmax: -13472670 ymax: 4683976\nProjected CRS: WGS 84 / Pseudo-Mercator\n\n# plot the groundwater levels at each monitoring site \ngwl %>% \n  ggplot() +\n  geom_line(aes(MSMT_DATE, WSE, group = SITE_CODE), alpha = 0.5)\n\n\n\n# slice the first station per group of groundwater level observations\ngwl_min <- gwl %>% \n  group_by(SITE_CODE) %>% \n  slice(1) %>% \n  ungroup() \n\n# visualize sites on a map\nggplot() +\n  geom_sf(data = sac) +\n  geom_sf(data = gwl_min, alpha = 0.5, color = \"blue\") +\n  theme_void()\n\n\n\n\nNotice that nrow(gwl) is greater than nrow(gwl_min), but length(unique(gwl$SITE_CODE)) equals length(unique(gwl_min$SITE_CODE)). We don’t need to plot all of the redundant gwl locations on the map, so we created a minimal tibble with only the unique SITE_CODEs, and hence, geometry.\nDuring the analysis, you realize you want to easily look at data by monitoring site, so you make a function that streamlines this.\n\n\n# function that takes a site code and generates a plot\nf_make_hydrograph <- function(data, site_code){\n  p <- data %>% \n    filter(SITE_CODE == site_code) %>% \n    ggplot(aes(MSMT_DATE, WSE)) +\n    geom_line(alpha = 0.5) +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    labs(title = glue::glue(\"Groundwater level (ft AMSL) at: {site_code}\"))\n  return(p)\n}\n\n# make a hydrograph for the first SITE_CODE\nf_make_hydrograph(gwl, gwl$SITE_CODE[1])\n\n\n\n\nYour supervisor requests figures from certain stations, and you find yourself re-running this function to generate them. You also have teammates that require subsets of these data per monitoring site, with specific columns in the output. You add a function that writes data to csv files to handle this task, but realize that this project is ongoing, and people will keep coming to you with requests for alternate combinations of plots or data. Also, the groundwater level data is sufficiently large and complex that you want to be able to view them all in one place.\n\nOne solution to automate the “data visualization exploration” and “data sharing” processes is by creating a Shiny App.\n\nIn the sections that follow, we will create a Shiny App that allows users to easily select and visualize groundwater data at different monitoring stations, and export data for a selected site.\nBasic Shiny App Structure\nAt the bare minimum, a Shiny App is an .R file or set of .R files with thee components: a ui, server and runApp(). The runApp() function takes the ui and the server objects and runs the Shiny web application.\nBy design, Shiny Apps separate front and back end components of the web application. The ui stands for “user interface” and defines front-facing components that the user sees and interacts with, like plots, tables, sliders, buttons, and so on. The server holds the back-end logic that accepts input from the user, and uses these inputs to define what data transformations should occur and what is passed back to the frontend for the user to view and interact with.\nIn order to demonstrate a simple Shiny App, we will use a single file called app.R defines a ui and server. Afterward, we will also discuss approaches to modularize an app into separate files - this may be necessary if an app becomes sufficiently complex.\nCreating a Shiny App\nThe most simple way to create an app within RStudio is to click File > New File > Shiny Web App….\n\n\n\nBy default, RStudio will create a new folder with a name you provide in your project directory2. Enter gwl_shiny as the “Application name” and click Create.\n\n\n\nYou should now have a folder called gwl_shiny in the project directory, which you can verify in the File Viewer Pane. Inside that folder should be a single file, app.R.\n\n\n\nA default Shiny App is contained in this file. We can run all of the code to view the app on our local machine, or click the Run App icon in the top right corner of the code editor.\n\n\n\nScroll through app.R and notice that there is a ui object, a server object which is a function of input and output, and a runApp() function which takes the ui and server objects as input.\nui (user interface)\nThe ui defines what the user sees when they interact with the Shiny App. Consider the following simple app with no server logic but that demonstrates a few of the control widget3 inputs available for Shiny Apps.\n\n\nlibrary(shiny)\n\nui <- fluidPage(\n    # generic example inputs in a sidebar\n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\n              \"bins\",\n              \"Slider Input\",\n              min = 1,\n              max = 50,\n              value = 30\n            ),\n            fileInput(\n              \"file\",\n              \"File Input\"\n            ),\n            dateInput(\n              \"date\",\n              \"Date Input\"\n            ),\n            textInput(\n              \"text\",\n              \"Text Input\"\n            ),\n            selectInput(\n              \"select\",\n              \"Select Input\",\n              choices = c(\"A\",\"B\",\"C\")\n            ),\n            radioButtons(\n              \"radio\",\n              \"Radio Buttons\",\n              choices = c(\"A\",\"B\")\n            )\n        ),\n        mainPanel(\"Look at all those inputs!\")\n    )\n)\n\n# server logic\nserver <- function(input, output) {}\n\n# run the Shiny app\nshinyApp(ui = ui, server = server)\n\n\n\n\n\n\nThese control widgets may be intuitive to you, as we’ve all interacted with web-based tools and apps before that use widgets like these. View a more comprehensive list of control widgets here.\nChances are that you won’t use all of the control widget inputs available in any given Shiny App you build. The choice of inputs you use will depend on what information you want to present to the user, and how information they select with those widgets should modify data in the server.\nserver\nIf the ui are the sensory organs that receive inputs, the server is the brain of the Shiny App that knows what to do with those inputs.\nother files\nSplit into 3 files: ui, server, global\nglobal, etc, modules\nShare and deploy a Shiny App\nUp until now, we’ve been using our own computer to run our Shiny App example. If we wanted to share the Shiny App, how might we do that?\nThe fastest and simplest way to share your Shiny app with another R user is to share the app.R file and data dependencies. They can open the file and run the app on their computer as we’ve been doing in this module. However, we may want to share our app with a wider, non-technical audience over the internet. When we move a Shiny App from our computer onto a web server so that it can be shared over the internet, we deploy the app.\nThere are a range of services that allow us to deploy Shiny Apps that range from simple to complex, and costly to inexpensive.\nA relatively painless way to deploy is via shinyapps.io, run by RStudio. A free tier is available for small applications, with a capped number of “live hours” per month to test your application. Paid tiers afford more “live hours” per month, a faster web server, and features like password protection.\n{shiny} is open source, and in that spirit, the open source Shiny Server can be installed on any cloud computer (e.g., AWS, Google Cloud, Microsoft Azure). If you don’t have a background in cloud computing, your System Administrator (Sys Admin) can help you move your App onto a cloud or company server4.\nExtending Shiny\nCongratulations! You’re now familiar with the basics of {shiny}. This module is just the tip of the iceberg. There are so many ways to extend {shiny}, and the opportunities for customization of Shiny Apps are vast. We recommend the following ways to increase your knowledge in this domain:\nfind open source Shiny Apps that you admire, clone their source code to your machine, run the App, and change things so you can explore how the App works. Borrow bits of code in new Apps you create\nfind a side project that’s a good candidate for a Shiny App and build one - it doesn’t need to be work related and in fact, it might be more fun to work on something tangential that you find interesting\nexplore the free online books and guided video tutorials in the links below\nAdditional Resources\nBelow are a few freely available books, presentations, and locations to find Apps online:\nRStudio Shiny Gallery: Examples of Shiny Apps highlighting different ways Shiny has been used, with links to source code\nMastering Shiny: Free online book that serves as an authoritative guide on how to build, maintain, deploy, and customize R Shiny Apps. Material goes well beyond what is presented in this module.\nGuided Shiny Video tutorials: Series of guided video tutorials with live-code demos and slides that explain the fundamentals of R Shiny Apps and how to use them.\n\n\nPrevious module:Interactive Visualization Next module:Reproducibility & Automation\n\nFor instance, imagine you are using the California Department of Water Resources’ Periodic Groundwater Level Database used throughout this course.↩︎\nIf using {here}, your project directory is here().↩︎\nA control widget is a tool that allows users to send information from the frontend ui to the backend server. Different widgets allow different types of information to pass between the ui and server.↩︎\nThe Shiny Server Administrator’s Guide](https://docs.rstudio.com/shiny-server/)) provides detailed documentation geared towards System Administrators that will help in deploying a Shiny App.↩︎\n",
      "last_modified": "2021-05-06T19:44:41-07:00"
    },
    {
      "path": "m_updating_r.html",
      "title": "Updating R and R packages",
      "description": "How to check versions and update your installation\n",
      "author": [],
      "contents": "\n\nContents\nChecking Versions and Updating\nCheck your    Version\nCheck/Update  \n\nUpdating R Packages\nBest Practices for Updating\n\n\nhtml{\n  scroll-behavior: smooth;\n}\nd-article {\n    contain: none;\n  }\n\nLearning objectives\nUnderstand R versions and how to check what you have\nLearn how to update your R/RStudio installation\nLearn how to update R packages\n\nChecking Versions and Updating\nAs packages and R continue to improve, new versions of R are released1. In R, major versions are released infrequently (i.e., 3.0.0 was released in April 2013 and 4.0.0 was released in April 2020), but minor versions are released more regularly (4.0.4 was released in February 2021 and 4.0.5 was released in March 2021).\nAt minimum it’s advisable to maintain and update to the most recent major version of R, as these often contain important security/programming changes. Depending on your workflow and package needs, it’s good practice to keep the most recent minor version as well, though it’s not uncommon to maintain multiple minor versions of R if your analyses or workflows depend on specific versions of a package.\nCheck your    Version\nAn easy and quick way to check what version of R you have and the most recent available version is first to open R, type R.version, hit enter, and see what you get:\n\n\nR.version\n\n\n               _                           \nplatform       x86_64-apple-darwin17.0     \narch           x86_64                      \nos             darwin17.0                  \nsystem         x86_64, darwin17.0          \nstatus                                     \nmajor          4                           \nminor          0.2                         \nyear           2020                        \nmonth          06                          \nday            22                          \nsvn rev        78730                       \nlanguage       R                           \nversion.string R version 4.0.2 (2020-06-22)\nnickname       Taking Off Again            \n\nThis command will return information about the R version your system is using, as well as some information specific to your operating system (os).\nNext, visit the R CRAN website to see what the most recent version is. If you haven’t updated recently, go ahead and grab the most recent R version for your system and install it.\nWhen you update a major version of R, your personal library of packages will no longer work, and you will need to reinstall all of your packages. There are a few tools you can use to do this like {installr} for Windows machines, and {updateR}. This work to stay up-to-date happens fairly infrequently.\nCheck/Update  \nWe can check our version of RStudio by going to the toolbar at the top of your RStudio window and clicking Help > Check for Updates. If you have the most recent version, there will be a message box letting you know as much. If not, RStudio will direct you to their webpage to download the most recent version.\nWhile it isn’t always necessary to update to the most recent version of R, there’s no reason not to always use the most recent stable version of RStudio. It will generally include the best features and up-to-date fixes.\nUpdating R Packages\nAs we use R more regularly for different tasks, it’s common to accumulate many R packages in our R library. Every package is maintained and updated on a different schedule than R and RStudio, and so as new functions and features are written, or bugs are fixed, packages will be updated intermittently. Some package maintainers do this regularly, others may do it sporadically. Either way, we will typically need to update packages semi-regularly.\nFiles associated with installed R packages are located at .libPaths(). View installed packages with list.files(.libPaths()).\nThere are several methods of updating your R packages. If updating via RStudio, go to the toolbar at the top and select Tools > Check for Package Updates.... Depending on how many packages you’ve installed, and how recently you updated things, a window will appear saying either All packages up-to-date! or something that looks more like this:\nAs a rule of thumb, whenever updating your R version, it’s best to update/install your R packages too!\n\n\n\nFigure 1: Package update window\n\n\n\nWe can choose to Select All and update everything at once, or selectively update things.\nAfter we click Install Updates we may typically also see a message like this:\n\n\n\nFigure 2: Restart R\n\n\n\nYou can choose to cancel, but it’s fine to click Yes and proceed. Sometimes we will also get something in the Console that will ask the following:\n\nDo you want to install from sources the packages which need compilation? (Yes/no/cancel)\n\nSome packages require this, so generally it’s okay to type Yes and hit enter to proceed. At this point we can wait and let R/RStudio update things for us. Depending on how many packages are involved, this can take a few minutes. Importantly, when it’s all said and done, make sure there weren’t errors or issues with packages that didn’t get installed. We can use Tools > Check for Package Updates... again and see what packages remain, or if we get a message saying all packages are up-to-date.\nBest Practices for Updating\nWe recommend the following approach to updating R packages (check out the great rstats.wtf chapter on this topic and more):\nUpdate packages frequently (weekly)\nUpdate R quarterly (or at least check)\nFor complete reproducibility for a project check out the {renv} package\nDon’t copy packages over between R versions–start clean and fresh\nUpdating packages can be irksome, but it’s typically for the best. We advise updating your packages frequently if you regularly use R (e.g;, a weekly checks and updates to packages). If you want to be sure you have the exact package version for future use and reproducibility, the {renv} may be a great solution for an analysis or report, but may not be necessary if your aren’t using or working on a specific project/analysis. {renv} keeps a record of your R packages within an RProject down to the exact version number when you originally loaded these packages, and allows you to update this record as your project evolves over time.\nRead more about {renv} in the project management module.\nOverall, treat R and R packages as something that will be highly functional with minimal but regular maintenance, like a vehicle that needs new tires or an oil change once in a while. This will keep things running smoothly over the long-term.\n\n\n\nFigure 3: Success over time! (Artwork by @allison_horst)\n\n\n\n\nSee a list of previous versions here.↩︎\n",
      "last_modified": "2021-05-05T12:58:23-07:00"
    }
  ],
  "collections": []
}
