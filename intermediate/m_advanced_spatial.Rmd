---
title: "Advanced spatial R and mapmaking"
description: | 
   From 1,000 point-clicks to 1 script...
output: 
  distill::distill_article:
    toc: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE, message=FALSE}

library(knitr)
library(glue)
library(here)

```

::: {.obj}
**Learning objectives**

-   Learn to extend and use {sf} for geospatial work
-   Understand the power of script-based geospatial/mapping
-   Expand your geospatial skills in R!
:::


## Overview

The ability to work in one place or with one program from start to finish is powerful and more efficient. By sticking with one single framework or set of tools, we can reduce the mental workload necessary when switch between programs, staying organized in each, and dealing with import/export across multiple programs. While different tools such as ESRI (or ArcPy extensions) are good, they require a paid license and typically still use point-click user interfaces.

The advantage `R` has over these other tools is that it is freely available, provides access to entire statistical/modeling toolboxes, and spatial analysis and mapmaking tools, all while remaining in a single place. 

If we use a functional programming approach (described in previous modules [link]() ) for spatial problems, `R` can be a very robust and powerful tool for analysis and spatial visualization of data! Furthermore, once analyses have been completed, we can re-use the scripts and functions for common spatial tasks (like making maps or exporting specific spatial files).

## Common Geospatial Tasks

There are some common tasks that are often required or repeated, and using a GUI-based approach, these tasks will always require the same number of point and clicks. With a script-based approach, it's much easier to recycle previous code, or just change a variable and re-run the code. This efficiency is magnified immensely when it can be automated or iterated over the same task through time, or multiple data sets.

For example, some common tasks may include:

 - Cropping/creating a specific region or subset of spatial data for different users
 - Making a map with common layers or components but updated data
 - Integrating or spatial joining of datasets
 - Reprojecting spatial data
 
## The power of a script-based analysis with `{sf}`

The `{sf}` package truly makes working with vector-based spatial data easy. We can use a pipeline that includes:

 - `st_read`: read spatial data in (e.g., shapefiles)
 - `st_transform`: transform or reproject data
 - `st_buffer`: buffer around data
 - `st_union`: combine data into one layer
 - `st_intersection`: crop or intersect one data by another
 - `group_split` & `st_write` to split data by a column or attribute and write out
 
There are many more options that can be added or subtracted from these pieces, but at the core, we can use this very functional approach to provide data, make maps, conduct analysis, and so much more.

## A Climate/Hydrology Example

Let's use an example where we take global climate data and crop it down to just an area of interest and then join it to additional data and write it back out a few counties of interest in California (Placer, Sacramento, San Joaquin, Sutter).

### The Packages

```{r libraries}

library(here)
library(sf)
library(dplyr)
library(viridis)
library(ggplot2)
# library(tigris)
library(USAboundaries)
library(rnaturalearth)
library(GSODR)
library(ggrepel)
library(cowplot)
library(mapview)      # interactive maps!
mapviewOptions(fgb = FALSE)

```

### Get State & County Data

First we want to get state and county boundaries. The {USAboundaries} package is excellent for this.

```{r boundaries}

# get USA states, filter out Puerto Rico, Alaska, and Hawaii for now
us <- USAboundaries::us_boundaries(type="state", resolution = "low") %>% 
  filter(!state_abbr %in% c("PR", "AK", "HI"))

# get CA boundary with high definition
ca <- USAboundaries::us_states(resolution = "high", states = "CA")

# make a box around CA (a grid with an n=1) for inset
ca_box <- st_make_grid(ca, n = 1)

# get CA county boundary
ca_co <- USAboundaries::us_counties(resolution = "high", states = "CA")

# make sure we have all the pieces with a quick test plot
plot(us$geometry)
plot(ca$geometry, add=T, col="gray50", border="maroon")
plot(ca_co$geometry, add=T, border="pink", col=NA)
plot(ca_box, add=T, border="red3", col=NA, lwd=2)

```

### Get Climate Data from the [GSODR](https://ropensci.github.io/GSODR/)

Next let's take historical global climate data stations and filter to just California counties of interest.

```{r}

# load the isd_history file:
load(system.file("extdata", "isd_history.rda", package = "GSODR"))

# make spatial
isd_history <- as.data.frame(isd_history) %>% 
  st_as_sf(coords=c("LON","LAT"), crs=4326, remove=FALSE)  

# filter to US and CA, many sites out in buoys along coast
isd_history_ca <- dplyr::filter(isd_history, CTRY=="US", STATE=="CA")

```

Now let's plot all the stations globally and see what we have. Here we can leverage the many points to actually help fill out our global outlines a bit (there are `r nrow(isd_history)` stations to work with!).

```{r, layout="l-page"}

# view!
library(rnaturalearth)
library(rnaturalearthdata)

# get countries
world <- ne_countries(scale = "medium", returnclass = "sf")

# plot
plot(isd_history$geometry, pch=16, cex=0.2, col="gray50")
plot(world$geometry, add=T, border = "gray10")
plot(ca$geometry, col="maroon", add=TRUE)
title("GSOD Climate Stations")

```


## Filter Data

Next we can zoom into just California. There are `r nrow(isd_history_ca)` total stations.

```{r, layout="l-page"}

# look at CA sites only
plot(ca$geometry, col=alpha("gray", 0.5), border="#440154FF", lwd=1.5)
plot(ca_co$geometry, add=T, border="purple", col=NA)
plot(isd_history_ca$geometry, add=T, pch=21, bg="#21908CFF", cex=0.7, col="black")
title("GSOD Climate Stations labeled as CA")
```

Ok! Let's quickly filter down to the counties of interest and look at joining these data.

## JOINS

First we filter to 4 specific counties, then join to the climate data stations. Note, we are using a spatial join here, which gets polygons that contain points.

```{r}

# get specific counties
ca_co_select <- ca_co %>% filter(name %in% 
                                   c("Sacramento", "Placer",
                                     "San Joaquin", "Sutter"))

# Get CA county POLYGONS that contain ISD points 
# does not bring attributes from points forward
ca_co_isd_poly <- ca_co_select[isd_history, ]

# anti_join: find counties that don't contain ISD points
ca_co_poly_anti <- ca_co[!lengths(st_intersects(ca_co, isd_history_ca)), ]

plot(ca_co_select$geometry, col=alpha("gray",0.3))
plot(ca_co_isd_poly$geometry, col=alpha("blue",0.3), add=TRUE)
plot(isd_history_ca$geometry, add=T, pch=21, bg="yellow", cex=1.2, col="black")
title("Counties with GSOD ISD Stations (blue)")
```

Ok, so there are 3 counties that have stations. Let's actually get the data from those counties and join to the nearest groundwater station associated with each.

### Get GSOD Data for Selected Stations

Here we use a spatial join to grab just the stations from our selected counties, and make a quick map with the mapview package.

```{r}

isd_select <- st_join(isd_history_ca, ca_co_isd_poly, left=FALSE)

mapview(isd_select, zcol="name", layer.name="County") +
  mapview(ca_co_isd_poly, alpha=0.5, legend=FALSE)

```

Then we can see what the longest data period is for these data and pull just one station per county.

```{r}

library(lubridate)

stations <- isd_select %>% 
  mutate(date_begin = ymd(BEGIN),
         date_end = ymd(END), 
         tot_yrs = time_length(interval(date_begin, date_end), "year"))

# if we want to take a look at this
stations %>% group_by(name) %>% 
  filter(tot_yrs == max(tot_yrs)) %>% 
  select(STNID:LON, tot_yrs) %>% 
  glimpse()

```


Use GSOD lesson and show climate stations with climate data, write out by county: https://ryanpeek.org/mapping-in-R-workshop/03_spatial_joins.html

You want to find the nearest river/WQ stations to a groundwater area of interest?

Spatial joins, st_nearest, buffering
Why click button GIS tasks may be easier to integrate with R? What if you needed to do this for each county or river?
End up with a list of stations/points that we can map with the buffer

How to pull spatial river data or other spatial data via R (nhdtoolsPlus package, dataRetrieval)

Adding more content on spatial operations (buffer, nearest, measurements)

Reading a zipped shapefile directly into R, use it, and move out!

Joins (spatial and non-spatial)
Join physical datasets with Redlining and CalEnviroScreen data
Join by census tract, or join by what points fall within a certain county or tract
Can use the climate station example too 

Mapping with layers: tmap and tmaptools
Show basemap options with tmaptools
Add elevation with elevatr

Mapedit and digitizing with R: how to create spatial objects from scratch from within R.
Save custom polygon using mapedit from temp object in R to rds
Select with mapedit and save 
