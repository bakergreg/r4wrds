---
title: "Advanced spatial R and mapmaking"
description: | 
   From 1,000 point-clicks to 1 script...
output: 
  distill::distill_article:
    toc: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE, message=FALSE}

library(knitr)
library(glue)
library(here)

```

::: {.obj}
**Learning objectives**

-   Learn to extend and use {sf} for geospatial work
-   Understand the power of script-based geospatial/mapping
-   Expand your geospatial skills in R!
:::


## Overview

The ability to work in one place or with one program from start to finish is powerful and more efficient. By sticking with one single framework or set of tools, we can reduce the mental workload necessary when switch between programs, staying organized in each, and dealing with import/export across multiple programs. While different tools such as ESRI (or ArcPy extensions) are good, they require a paid license and typically still use point-click user interfaces.

The advantage `R` has over these other tools is that it is freely available, provides access to entire statistical/modeling toolboxes, and spatial analysis and mapmaking tools, all while remaining in a single place. 

If we use a functional programming approach (described in previous modules [link]() ) for spatial problems, `R` can be a very robust and powerful tool for analysis and spatial visualization of data! Furthermore, once analyses have been completed, we can re-use the scripts and functions for common spatial tasks (like making maps or exporting specific spatial files).

## Common Geospatial Tasks

There are some common tasks that are often required or repeated, and using a GUI-based approach, these tasks will always require the same number of point and clicks. With a script-based approach, it's much easier to recycle previous code, or just change a variable and re-run the code. This efficiency is magnified immensely when it can be automated or iterated over the same task through time, or multiple data sets.

For example, some common tasks may include:

 - Cropping/creating a specific region or subset of spatial data for different users
 - Making a map with common layers or components but updated data
 - Integrating or spatial joining of datasets
 - Reprojecting spatial data
 
## The power of a script-based analysis with `{sf}`

The `{sf}` package truly makes working with vector-based spatial data easy. We can use a pipeline that includes:

 - `st_read`: read spatial data in (e.g., shapefiles)
 - `st_transform`: transform or reproject data
 - `st_buffer`: buffer around data
 - `st_union`: combine data into one layer
 - `st_intersection`: crop or intersect one data by another
 - `group_split` & `st_write` to split data by a column or attribute and write out
 
There are many more options that can be added or subtracted from these pieces, but at the core, we can use this very functional approach to provide data, make maps, conduct analysis, and so much more.

## A Climate/Hydrology Example

Let's use an example where we take global climate data and crop it down to just an area of interest and then join it to additional data and write it back out a few counties of interest in California (Placer, Sacramento, San Joaquin, Sutter).

### The Packages

```{r libraries}

library(here)
library(sf)
library(dplyr)
library(viridis)
library(ggplot2)
# library(tigris)
library(USAboundaries)
library(rnaturalearth)
library(GSODR)
library(ggrepel)
library(cowplot)
library(mapview)      # interactive maps!
mapviewOptions(fgb = FALSE)

```

### Get State & County Data

First we want to get state and county boundaries. The {USAboundaries} package is excellent for this.

```{r boundaries}

# get USA states, filter out Puerto Rico, Alaska, and Hawaii for now
us <- USAboundaries::us_boundaries(type="state", resolution = "low") %>% 
  filter(!state_abbr %in% c("PR", "AK", "HI"))

# get CA boundary with high definition
ca <- USAboundaries::us_states(resolution = "high", states = "CA")

# make a box around CA (a grid with an n=1) for inset
ca_box <- st_make_grid(ca, n = 1)

# get CA county boundary
ca_co <- USAboundaries::us_counties(resolution = "high", states = "CA")

# make sure we have all the pieces with a quick test plot
plot(us$geometry)
plot(ca$geometry, add=T, col="gray50", border="maroon")
plot(ca_co$geometry, add=T, border="pink", col=NA)
plot(ca_box, add=T, border="red3", col=NA, lwd=2)

```

### Get Climate Data from the [GSODR](https://ropensci.github.io/GSODR/)

Next let's take historical global climate data stations (Global Surface Summary of the Day=GSOD^[ For more about the GSOD data, see NOAA's site [here](https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00516)]) and filter to stations that are just in California.

```{r}

# load the isd_history file:
load(system.file("extdata", "isd_history.rda", package = "GSODR"))

# make spatial
isd_history <- as.data.frame(isd_history) %>% 
  st_as_sf(coords=c("LON","LAT"), crs=4326, remove=FALSE)  

# filter to US and CA, many sites out in buoys along coast
isd_history_ca <- dplyr::filter(isd_history, CTRY=="US", STATE=="CA")

```

Now let's plot all the stations globally and see what we have. Here we can leverage the many points to actually help fill out our global outlines a bit (there are `r nrow(isd_history)` stations to work with!).

```{r, layout="l-page"}

# view!
library(rnaturalearth)
library(rnaturalearthdata)

# get countries
world <- ne_countries(scale = "medium", returnclass = "sf")

# plot
plot(isd_history$geometry, pch=16, cex=0.2, col="gray50")
plot(world$geometry, add=T, border = "gray10")
plot(ca$geometry, col="maroon", add=TRUE)
title("GSOD Climate Stations")

```


## Filter Data

Next we can zoom into just California. There are `r nrow(isd_history_ca)` total stations we can work with, but not all counties have stations.

```{r, layout="l-page"}

# look at CA sites only
plot(ca$geometry, col=alpha("gray", 0.5), border="#440154FF", lwd=1.5)
plot(ca_co$geometry, add=T, border="purple", col=NA)
plot(isd_history_ca$geometry, add=T, pch=21, bg="#21908CFF", cex=0.7, col="black")
title("GSOD Climate Stations labeled as CA")
```



## Filters & Spatial Joins

Ok! Let's quickly filter down to the counties of interest (Placer, Sacramento, San Joaquin, Sutter), and select a single station from each county that has a station.

First we filter to 4 specific counties, then join to the climate data stations. Note, we are using a spatial join here, which gets polygons that contain points. We can also use an anti_join (the `!`) to find counties that contain *no* stations. These operations can be helpful when exploring and understanding a dataset, to identify gaps, highlight specific areas, etc.

```{r, layout="l-page"}

# get specific counties
ca_co_select <- ca_co %>% filter(name %in% 
                                   c("Sacramento", "Placer",
                                     "San Joaquin", "Sutter"))

# check CRS is the same
identical(st_crs(ca_co_select)$epsg, st_crs(isd_history)$epsg)

# SPATIAL JOIN: Get CA county POLYGONS that contain ISD points 
# does not bring attributes from points forward
ca_co_isd_poly <- ca_co_select[isd_history_ca, ]

# anti_join: find counties that don't contain ISD points
ca_co_poly_anti <- ca_co[!lengths(st_intersects(ca_co, isd_history_ca)), ]

# plot of all CA counties with and without ISD stations
plot(ca_co$geometry, col=alpha("gray70",0.3))
#plot(ca_co_select$geometry, col=alpha("gray",0.3))
plot(ca_co_poly_anti$geometry, col=alpha("purple",0.3), add=TRUE)
plot(ca_co_isd_poly$geometry, col=alpha("forestgreen",0.6), add=TRUE)
plot(isd_history_ca$geometry, add=T, pch=21, bg="yellow", cex=0.8, col="black")
title("Counties with GSOD ISD Stations (green)\n No Stations (purple)")
```

Ok, so there are 3 counties from our list that have GSOD stations. Let's find out some more info on the specific stations from our counties of interest, and pull one station per county. In this case, let's pull the station that has the most data (or longest period of time), so we can join these data to the nearest groundwater station.

## Select GSOD Stations for Selected Counties

Here we use `st_join` directly to filter points that fall within polygons. Here, that's the GSOD stations that fall within our selected counties. 

<aside>
When we have 2 `{sf}` dataframes, we can also spatially join using the `[ ]` notation as we did in the county joins above. `st_join()` and `[ ]` are equivalent when spatial data shares the same CRS.
</aside>

```{r}

isd_select <- st_join(isd_history_ca, ca_co_isd_poly, left=FALSE)

mapview(isd_select, zcol="name", layer.name="County") +
  mapview(ca_co_isd_poly, alpha=0.5, legend=FALSE)

```

### Writing Spatial Data Out

We may want to save these data and send to colleagues before we proceed with further analysis. As we've shown before, functional programming is a great option, and we can create a function to split data and write it out for future use, or to share and distribute. Here we are using a fairly simple example, but the concept can be expanded.

Let's use the `{purrr}` package to iterate over two different lists and write them to a geopackage (a self contained spatial database). Geopackages are a great way to save vector-based spatial data, they can be read by ArcGIS and spatial software, and they are compact and self-contained (unlike shapefiles).

```{r, echo=TRUE, eval=FALSE}
library(purrr)
library(janitor)

# first split ISD data by county:
isd_select_split <- isd_select %>% 
  rename(cnty_name=name) %>% # avoid duplicate names
  split(.$cnty_name) # split by cnty name

# split county data by county
ca_co_select_split <- ca_co_isd_poly %>% 
  rename(cnty_name=name) %>% # avoid duplicate names
  split(.$cnty_name) # split by cnty name

# make a list of clean names with janitor pkg
(clean_cnty_names <- make_clean_names(ca_co_isd_poly$name))

# now apply function to write out points by county
map2(isd_select_split, # list of points
     clean_cnty_names, #list of cnty names
     ~st_write(.x, 
               dsn = glue("data/{.y}_gsod.gpkg"),
               layer = glue("{.y}_isd_pts")))

# to add additional layers we can do the same with a diff layer
map2(ca_co_select_split, # list of points
     clean_cnty_names, #list of cnty names
     ~st_write(.x, 
               dsn = glue("data/{.y}_gsod.gpkg"),
               layer = glue("{.y}_isd_cnty")))

# check layers in one of gpkg files:
st_layers("data/placer_gsod.gpkg")

```


## Filter Data

Now we have a subset of stations to use, let's filter these down to one per county for now. Let's use the station that has the longest period of record, and we can then pair this with the nearest groundwater station.

```{r}

library(lubridate)

# calculate the duration of data for each station
stations <- isd_select %>% 
  mutate(date_begin = ymd(BEGIN),
         date_end = ymd(END), 
         tot_yrs = time_length(interval(date_begin, date_end), "year"))

# group by county name
stations %>% group_by(name) %>% 
  # get the station with the longest set of data
  filter(tot_yrs == max(tot_yrs)) %>% 
  select(STNID:LON, tot_yrs) %>% 
  glimpse()

```


Use GSOD lesson and show climate stations with climate data, write out by county: https://ryanpeek.org/mapping-in-R-workshop/03_spatial_joins.html

You want to find the nearest river/WQ stations to a groundwater area of interest?

Spatial joins, st_nearest, buffering
Why click button GIS tasks may be easier to integrate with R? What if you needed to do this for each county or river?
End up with a list of stations/points that we can map with the buffer

How to pull spatial river data or other spatial data via R (nhdtoolsPlus package, dataRetrieval)

Adding more content on spatial operations (buffer, nearest, measurements)

Reading a zipped shapefile directly into R, use it, and move out!

Joins (spatial and non-spatial)
Join physical datasets with Redlining and CalEnviroScreen data
Join by census tract, or join by what points fall within a certain county or tract
Can use the climate station example too 

Mapping with layers: tmap and tmaptools
Show basemap options with tmaptools
Add elevation with elevatr

Mapedit and digitizing with R: how to create spatial objects from scratch from within R.
Save custom polygon using mapedit from temp object in R to rds
Select with mapedit and save 
